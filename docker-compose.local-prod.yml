version: '3.8'

services:
  # ==========================================================================
  # POSTGRESQL - Banco de dados de PRODU√á√ÉO LOCAL
  # ==========================================================================
  postgres:
    image: postgres:16-alpine
    container_name: petshop-local-prod-postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-petshop_local_prod}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-CHANGE_THIS_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB:-petshop_local_prod_db}
      - POSTGRES_INITDB_ARGS=--encoding=UTF8 --locale=C
    volumes:
      - postgres-local-prod-data:/var/lib/postgresql/data
    networks:
      - local-prod-network
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-petshop_local_prod} -d ${POSTGRES_DB:-petshop_local_prod_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    ports:
      - "5433:5432"  # Porta diferente para n√£o conflitar com staging

  # ==========================================================================
  # BACKEND - FastAPI + SQLAlchemy
  # ==========================================================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: petshop-local-prod-backend
    ports:
      - "8001:8000"  # Porta 8001 para produ√ß√£o local
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - RUNNING_IN_DOCKER=true
      - DATABASE_URL=postgresql+psycopg2://${POSTGRES_USER:-petshop_local_prod}:${POSTGRES_PASSWORD:-CHANGE_THIS}@postgres:5432/${POSTGRES_DB:-petshop_local_prod_db}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - ADMIN_TOKEN=${ADMIN_TOKEN}
      - FRONTEND_URL=${FRONTEND_URL:-http://localhost:5173}
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-http://localhost:5173,http://localhost:3000}
      - GOOGLE_MAPS_API_KEY=${GOOGLE_MAPS_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - BLING_CLIENT_ID=${BLING_CLIENT_ID:-}
      - BLING_CLIENT_SECRET=${BLING_CLIENT_SECRET:-}
      - RATE_LIMIT_ENABLED=true
      - RATE_LIMIT_PER_MINUTE=${RATE_LIMIT_PER_MINUTE:-120}
    volumes:
      - uploads-local-prod:/app/uploads
    networks:
      - local-prod-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ==========================================================================
  # BACKUP - Backup 2x ao dia para dados reais
  # ==========================================================================
  backup:
    image: postgres:16-alpine
    container_name: petshop-local-prod-backup
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-petshop_local_prod}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-CHANGE_THIS}
      - POSTGRES_DB=${POSTGRES_DB:-petshop_local_prod_db}
      - PGPASSWORD=${POSTGRES_PASSWORD:-CHANGE_THIS}
      - BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-30}
    volumes:
      - ./backups:/backups
    networks:
      - local-prod-network
    depends_on:
      postgres:
        condition: service_healthy
    restart: always
    # Backup a cada 6 horas (4x ao dia) para dados reais
    command: >
      sh -c "
      echo 'üîê Backup service started - Running every 6 hours for REAL DATA';
      while true; do
        TIMESTAMP=$$(date +%Y%m%d_%H%M%S);
        echo '[$(date)] Starting backup...';
        PGPASSWORD=$$POSTGRES_PASSWORD pg_dump -h postgres -U $$POSTGRES_USER -d $$POSTGRES_DB -F c -f /backups/backup_$$TIMESTAMP.dump;
        if [ $$? -eq 0 ]; then
          echo '[$(date)] ‚úì Backup completed: backup_$$TIMESTAMP.dump';
          gzip /backups/backup_$$TIMESTAMP.dump;
          echo '[$(date)] ‚úì Compressed: backup_$$TIMESTAMP.dump.gz';
          find /backups -name 'backup_*.dump.gz' -mtime +$${BACKUP_RETENTION_DAYS:-30} -delete;
          echo '[$(date)] ‚úì Old backups cleaned (retention: $${BACKUP_RETENTION_DAYS:-30} days)';
        else
          echo '[$(date)] ‚úó ERROR: Backup failed!';
        fi;
        echo '[$(date)] Next backup in 6 hours...';
        sleep 21600;
      done
      "
    healthcheck:
      test: ["CMD-SHELL", "ls /backups/backup_*.dump.gz | tail -1"]
      interval: 1h
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # ==========================================================================
  # MIGRATE - Execu√ß√£o isolada de migrations
  # ==========================================================================
  migrate:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: petshop-local-prod-migrate
    environment:
      - DATABASE_URL=postgresql+psycopg2://${POSTGRES_USER:-petshop_local_prod}:${POSTGRES_PASSWORD:-CHANGE_THIS}@postgres:5432/${POSTGRES_DB:-petshop_local_prod_db}
      - ENVIRONMENT=production
    networks:
      - local-prod-network
    depends_on:
      postgres:
        condition: service_healthy
    command: ["alembic", "upgrade", "head"]
    profiles:
      - migration

# ==========================================================================
# NETWORKS
# ==========================================================================
networks:
  local-prod-network:
    driver: bridge
    name: petshop-local-prod-network

# ==========================================================================
# VOLUMES
# ==========================================================================
volumes:
  postgres-local-prod-data:
    driver: local
    name: petshop-local-prod-postgres-data
  uploads-local-prod:
    driver: local
    name: petshop-local-prod-uploads
