"""
Intent Classifier

Classifica a inten√ß√£o do usu√°rio de forma r√°pida (GPT-4o-mini).
Usado para roteamento e m√©tricas.

Inten√ß√µes suportadas:
- saudacao: Ol√°, oi, bom dia
- consulta_produto: Perguntas sobre produtos
- consulta_preco: Perguntas sobre pre√ßo
- consulta_estoque: Disponibilidade
- consulta_entrega: Prazos, frete, hor√°rios
- pedido_recompra: Repetir pedido anterior
- pedido_novo: Fazer novo pedido
- reclamacao: Problemas, insatisfa√ß√£o
- suporte: D√∫vidas gerais
- despedida: Tchau, obrigado
- outro: N√£o classificado
"""
import logging
from typing import Dict, Literal
from app.ai.llm_client import LLMClient

logger = logging.getLogger(__name__)

# Type hint para inten√ß√µes
IntentType = Literal[
    "saudacao",
    "consulta_produto",
    "consulta_preco", 
    "consulta_estoque",
    "consulta_entrega",
    "pedido_recompra",
    "pedido_novo",
    "reclamacao",
    "suporte",
    "despedida",
    "outro"
]


class IntentClassifier:
    """
    Classifica inten√ß√£o usando GPT-4o-mini (r√°pido e barato).
    """
    
    def __init__(self, openai_api_key: str):
        self.llm = LLMClient(api_key=openai_api_key)
    
    async def classify(self, message: str, context: Dict = None) -> Dict[str, any]:
        """
        Classifica inten√ß√£o da mensagem.
        
        Args:
            message: Mensagem do usu√°rio
            context: Contexto adicional (hist√≥rico, cliente, etc)
            
        Returns:
            {
                "intent": "consulta_produto",
                "confidence": 0.95,
                "entities": {"produto": "ra√ß√£o", "marca": "golden"}
            }
        """
        try:
            # System prompt para classifica√ß√£o
            system_prompt = self._build_classification_prompt()
            
            # Mensagem do usu√°rio
            user_message = f"Classifique a inten√ß√£o: '{message}'"
            
            # Adicionar contexto se dispon√≠vel
            if context and context.get("historico_conversa"):
                last_messages = context["historico_conversa"][-3:]
                history_text = "\n".join([
                    f"{msg['tipo']}: {msg['conteudo']}" 
                    for msg in last_messages
                ])
                user_message += f"\n\nContexto recente:\n{history_text}"
            
            # Chamar LLM (for√ßa GPT-4o-mini para velocidade)
            response = await self.llm.chat_completion(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                model="gpt-4o-mini",
                temperature=0.3,  # Baixa temperatura para mais consist√™ncia
                max_tokens=150
            )
            
            # Parsear resposta
            content = response["content"].strip()
            result = self._parse_classification(content)
            
            logger.info(f"‚úÖ Intent: {result['intent']} (confidence: {result['confidence']})")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Erro ao classificar inten√ß√£o: {e}")
            return self._fallback_classification(message)
    
    def _build_classification_prompt(self) -> str:
        """Constr√≥i prompt de classifica√ß√£o."""
        return """Voc√™ √© um classificador de inten√ß√µes para um pet shop.

Classifique a mensagem do usu√°rio em UMA das seguintes categorias:

1. saudacao - Cumprimentos iniciais (oi, ol√°, bom dia)
2. consulta_produto - Perguntas sobre produtos espec√≠ficos
3. consulta_preco - Perguntas sobre valores
4. consulta_estoque - Disponibilidade de produtos
5. consulta_entrega - Frete, prazo, hor√°rio de entrega
6. pedido_recompra - Quer repetir pedido anterior
7. pedido_novo - Quer fazer novo pedido
8. reclamacao - Insatisfa√ß√£o, problema
9. suporte - D√∫vidas gerais, ajuda
10. despedida - Encerramento (tchau, obrigado)
11. outro - N√£o se encaixa nas categorias acima

Responda APENAS no formato:
INTENT: [categoria]
CONFIDENCE: [0.0-1.0]
ENTITIES: {key: value, ...}

Exemplo:
INTENT: consulta_produto
CONFIDENCE: 0.95
ENTITIES: {"produto": "ra√ß√£o", "marca": "golden", "tipo": "filhote"}
"""
    
    def _parse_classification(self, content: str) -> Dict:
        """Parseia resposta do LLM."""
        try:
            lines = content.strip().split("\n")
            result = {
                "intent": "outro",
                "confidence": 0.5,
                "entities": {}
            }
            
            for line in lines:
                if line.startswith("INTENT:"):
                    result["intent"] = line.split(":", 1)[1].strip()
                elif line.startswith("CONFIDENCE:"):
                    result["confidence"] = float(line.split(":", 1)[1].strip())
                elif line.startswith("ENTITIES:"):
                    entities_str = line.split(":", 1)[1].strip()
                    try:
                        import json
                        result["entities"] = json.loads(entities_str)
                    except:
                        result["entities"] = {}
            
            return result
            
        except Exception as e:
            logger.warning(f"Erro ao parsear classifica√ß√£o: {e}")
            return self._fallback_classification(content)
    
    def _fallback_classification(self, message: str) -> Dict:
        """
        Classifica√ß√£o baseada em regras (fallback).
        Usado quando LLM falha.
        """
        message_lower = message.lower()
        
        # Regras simples
        if any(word in message_lower for word in ["oi", "ol√°", "ola", "bom dia", "boa tarde", "boa noite"]):
            return {"intent": "saudacao", "confidence": 0.8, "entities": {}}
        
        if any(word in message_lower for word in ["tchau", "obrigado", "obrigada", "valeu", "at√©"]):
            return {"intent": "despedida", "confidence": 0.8, "entities": {}}
        
        if any(word in message_lower for word in ["pre√ßo", "preco", "valor", "quanto custa", "quanto √©"]):
            return {"intent": "consulta_preco", "confidence": 0.7, "entities": {}}
        
        if any(word in message_lower for word in ["tem", "t√™m", "estoque", "dispon√≠vel", "disponivel"]):
            return {"intent": "consulta_estoque", "confidence": 0.7, "entities": {}}
        
        if any(word in message_lower for word in ["entrega", "frete", "prazo", "demora"]):
            return {"intent": "consulta_entrega", "confidence": 0.7, "entities": {}}
        
        if any(word in message_lower for word in ["repetir", "mesmo pedido", "anterior", "de novo"]):
            return {"intent": "pedido_recompra", "confidence": 0.7, "entities": {}}
        
        if any(word in message_lower for word in ["comprar", "quero", "pedido", "pedir"]):
            return {"intent": "pedido_novo", "confidence": 0.6, "entities": {}}
        
        if any(word in message_lower for word in ["problema", "reclama√ß√£o", "reclamacao", "insatisfeito", "ruim"]):
            return {"intent": "reclamacao", "confidence": 0.8, "entities": {}}
        
        # Default
        return {"intent": "consulta_produto", "confidence": 0.5, "entities": {}}


# ============================================================================
# ROUTER DE INTENTS (decide a√ß√£o baseada na inten√ß√£o)
# ============================================================================

class IntentRouter:
    """
    Decide qual a√ß√£o tomar baseado na inten√ß√£o.
    """
    
    @staticmethod
    def should_transfer_to_human(intent: str, confidence: float) -> bool:
        """
        Decide se deve transferir para humano.
        
        Transfere se:
        - Reclama√ß√£o
        - Confidence muito baixa
        - Intent "suporte" espec√≠fico
        """
        if intent == "reclamacao":
            return True
        
        if confidence < 0.4:
            return True
        
        return False
    
    @staticmethod
    def requires_context_enrichment(intent: str) -> bool:
        """
        Decide se precisa buscar contexto adicional no ERP.
        
        Busca contexto para:
        - Consultas de produto/pre√ßo/estoque
        - Pedidos
        """
        needs_context = [
            "consulta_produto",
            "consulta_preco",
            "consulta_estoque",
            "pedido_recompra",
            "pedido_novo"
        ]
        
        return intent in needs_context
    
    @staticmethod
    def get_quick_response(intent: str, bot_name: str = "Assistente") -> str:
        """
        Resposta r√°pida para intents simples (sem chamar IA).
        
        Usado para sauda√ß√µes e despedidas.
        """
        quick_responses = {
            "saudacao": f"üêæ Ol√°! Sou o {bot_name}, como posso ajudar voc√™ e seu pet hoje?",
            "despedida": "At√© logo! Qualquer coisa √© s√≥ chamar! üêæ",
        }
        
        return quick_responses.get(intent)
    
    @staticmethod
    def should_use_advanced_model(intent: str, context: Dict) -> bool:
        """
        Decide se deve usar GPT-4.1 (modelo avan√ßado).
        
        Usa modelo avan√ßado para:
        - Pedidos complexos
        - M√∫ltiplas consultas
        - Recomenda√ß√µes
        """
        advanced_intents = [
            "pedido_novo",
            "pedido_recompra"
        ]
        
        if intent in advanced_intents:
            return True
        
        # Se conversa longa
        if context.get("session", {}).get("message_count", 0) > 5:
            return True
        
        return False
